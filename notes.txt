Data Science Project 

Data Gathering
marrinetraffic.com 
used the network tab in the inspect window to find where the website sends get request to the backend 
found that it sends get request to https://www.marinetraffic.com/getData/get_data_json_4/z:0/X:0/Y:0/station:0
therefore I sent it as well and got the json data 
https://www.marinetraffic.com/getData/get_data_json_4/z:1/X:0/Y:0/station:0
After exploring a little bit, I found that z is the zoom value 
when z = 0 we're zoomed out completely and only have x=0 y=0 value accessible (still 2.5k entries)
so z=1 and permutating over x and y values with 00 01 10 and 11 values we have the 4 json files
Each request gives up to 2.5 thousand entries. Combined scraping gets us around 10 thousand entries
this is good enough data to analyze and hopefully do some machine learning on

converted it to CSV using pandas using script.py

Goals
An optimistic outlook on opportunities (before analysis of if it's really possible, ideas on what we can do with the data):
VIS
-> port traffic analysis 
-> heatmaps of vessel density and traffic patterns 
ML
-> Vessel Type Classification based on movement patterns
-> Anomaly detection (unusual speed patterns, eg. cargo ship moving at 200 knots)
-> Suspicious movement patterns (would require continuous data overtime)

features that would help: 
LAT LON SPEED COURSE 
SHIPTYPE STATUS_NAME TYPE_NAME
Vessel Dimensions 


Data Exploration
firstly, the usage of AI to speed up the process of coding without worrying of syntax was a lot in this project
in terms of data exploration, the first objective was to understand what each column meant and how they relate to each other 
understanding the coverage of data in terms of how many NaN values vs valid values
if it was possible to fill up NaN values using the other data 
seeing which columns could be dropped that pose no significant value (feature engineering)
to explore we first use some general functions of pandas like .info .describe etc
from this we understand a little about the expanse of ships around the maps
latitude's range being -67 to 81 degrees (basically from antarctica to north, as low and as high as the ships can go)
longitude's range from -179 to 179 (covers the map)
both are perfect, cover the entire map, we can say we have scraped all the ship data of one particular moment in time
Remark: the use of common sense and general knowledge is greatly helpful in data analytics
if it's financial analysis of a business, knowing about that business would help!

An acute observation of speed is when I scraped in the morning the max speed was 1200 knots, and now it's 405 knots
basically ships slow down at night because of the tides! 

ROT is just rate of turning, it can be filled up with 0 for ships with a lot of speed since they won't be turning at all 
(they would be on course)
SHIPTYPE and TYPE_IMG have a lot of similarities, maybe they indicate the same thing
but SHIPTYPE has more coverage, if they're always equal, we can use SHIPTYPE to infer TYPE_NAME
this will increase the coverage of the categorized column, helpful in classification problems

SPEED's histogram gives a uniform distribution with two peaks, one around 0-20 range and the other at 120 range
this means a lot of ships stationary are being counted, we have a diverse dataset without biases towards one type
dropping the stationary ships with speed 0 and overlaying the graph on the prior histogram, my prediction was right
the peak at 0-20 range got smaller but still exists, maybe they are yachts or something 

Pleasure Craft have the highest record speeds of 405 knots

There's no correlation with boat length and speed, all three categories (<50m, 50-150m, >150m) have equivalent mean speeds
however larger boats are generally 50 knots faster

HEADING vs COURSE
heading is where the front of ship points
course is where the ship is moving towards
can happen that ship is backwards moving due to waves (which is problematic)
we can calculate max angular difference between them (very useful) (higher value = more out of alignment = problem) 
for low / no speed the angular difference doesn't matter as much 
for high speeds (10 - 1000) the distribution is normal except for outliers (0 25 50 and 75 are all < 5 but max is 180)
this 180 outlier could be possible that satellite mistook the ship's head for its tail
but higher angular differences for higher speeds = wind and waves are blowing ships away 
plotting speed v/s length and marking the angle difference greater than 90 as red triangles
we see that there's no true correlation between "danger" that we suspected and speed OR length
all ships are subject to this "swaying" from the wind / waves therfore there's no valuable classification to be done 

plotting ROT doesn't give any useful insight either, we just understand that there are a lot of ships that are currently 
not rotating therfore we can replace the NaN values with 0 there (given HC_DIFF_ABS is < some logical threshold)
and speed is > than some other threshold
the reason is if the angular difference is greater, it means the ship is not on its course
and if speed is less it means they're just "thinking" of course correction or something 
ALTHOUGH to save computational costs if this data is being used in the real world, we can see through the ROT v/s speed plot
that MOST of the NaN values for ROT are at high speeds or near 0 speeds. (ship has stopped / moving on correct course)
both of which do not need rotation, therefore we can replace ALL NaN values with 0 to make it a usable feature in our dataset

a simple linear regression can fit the width to length plot 

some width values were 0 for some reason.
TODO: find the reason why some width values were 0, they should've been NaN atleast? 

key thing I'm doing is AI had given TYPE_NAME against the width but all entries that have TYPE_NAME don't have width... 
Instead I'm using SHIPTYPE since it's ACTUALLY the same thing as we saw previously, therefore using the correlation between
TYPE_IMG and TYPE_NAME given to us, and TYPE_IMG == SHIPTYPE, and SHIPTYPE having more coverage, we've converted SHIPTYPE
into the categorical names that TYPE_NAME gave us.
From SHIPTYPE v/s LW_RATIO we can see some really sweet correlations such as Fishing ships are longer, Cargo Vessels are more "chonky". 

DWT (Deadweight Tonnage) v/s SHIPTYPE is kind of obvious

Elapsed is kind of useless since we aren't doing any real time analysis

Plotting the graph using Latitude and Longitude REALLY gives the feeling of working with marine data
It sort of looks like the map of the world!

speed v/s Geographic location! (also the range of color goes from 0-99.9% being 0 to 210)
the reason is that even if max is 405, it's an outlier which shifts the color spectrum of graph too high 
and most of fast ships are not that visible because the top one is TOO fast

using seaborn to look at the confusion matrix of the correlation of the numerical elements with each other
we see that heading and course relate, DWT and width, lenth have good relation, width and length also have good relation
this is where we start to understand what can be used as features to make predictions

Anomaly Detection Attempt (using z-scores)
tried creating anomaly scores for SPEED, HC_DIFF, and ROT to find unusual behavior
SPEED_ZSCORE worked okay, properly normalized with mean=0 std=1, max z-score was 5.83 (6 deviations away)
but HC_DIFF was pretty useless as an anomaly indicator:
-> mean is only 8.63 degrees
-> 50% of ships have HC_DIFF = 0 (median = 0) 
-> 75% have HC_DIFF â‰¤ 1 degree
-> from earlier we saw that large HC_DIFF values were mostly legitimate anyway (ships turning, drifting from wind/waves)
ROT_ZSCORE was even MORE useless:
-> 50% of values are 0, 75% are STILL 0
-> most ships just aren't turning at all if they're on course
-> only 2744 out of 10141 ships even have ROT data (27% coverage)
-> z-score is heavily skewed because of this

anomaly scoring with z-scores didn't really work here
HC_DIFF and ROT being zero or near-zero is just normal ship operation, not anomalies
the distributions are too skewed for z-scores to capture meaningful deviations
better to use domain-specific rules like "moving but anchored" or "stationary but underway" 
those are ACTUAL operational anomalies, not just statistical outliers


---

Okay, from the goals we had decided, we did the visualization part of density and heatmap
for ML, classification according to movement patterns is POSSIBLE, if we collectively use all other features wisely 
to predict the SHIPTYPE, gotta explore that. 
but anomaly and suspicious movement pattern is not possible since through analysing correlations between data, 
we can see it's not that great

